在计算机眼中，一张 512x512 分辨率的图片，就是一组 512 * 512 * 3 的数字，如果直接对图片进行学习，相当于 AI 要处理 786432 维的数据，这对算力、计算机性能要求很高。



CompVis 的研究人员提出，可以将图片映射到潜在空间（Latent Space）后进行扩散和逆扩散学习。如何理解 “潜在空间” 呢？大家都有自己的身份证号码，前 6 位代表地区、中间 8 位代表生日、后 4 位代表个人其他信息。放到空间上如图所示，这个空间就是「人类潜在空间」。



这个空间上相近的人，可能就是生日、地区接近的人。人可以对应为这个空间的一个点，这个空间的一个点也对应一个人。如果在空间中我的附近找一个点，对应的人可能跟我非常相似，没准就是我失散多年的兄弟 hh

AI 就是通过学习找到了一个「图片潜在空间」，每张图片都可以对应到其中一个点，相近的两个点可能就是内容、风格相似的图片。



同时这个 “潜在空间” 的维度（比如可能是 768）远小于 “像素维度”（786432），AI 处理起来会更加得心应手，在保持效果相同甚至更好的情况下，潜在扩散模型对算力、显卡性能的要求显著降低。这也就是为什么 Stable Diffusion 能在消费级显卡上运行，从而让 AI 绘画 “飞入寻常百姓家”。

说句题外话，我非常想知道为什么 Stable Diffusion 叫 Stable Diffusion，但没找到官方说明，这里做一个猜测：之所以这个基于 Latent Diffusion 的模型叫 Stable Diffusion，可能一方面表示这个模型效果很稳定（Stable），另一方面是致敬一下（算力 & 数据上的）金主爸爸 Stability.ai。