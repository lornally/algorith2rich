> 预习目标: 用numpy手撸一个神经网络
> 课前练习, 不求完全理解, 追求的是一个整体的认知
> 代码调通之后, 请务必花时间回顾一下, 看看代码是如何运转的
> 因为, 调用了各种库函数, 因此, 如果不参考任何内容, 大家是无法徒手写出来的. 这也是算法工程师日常的工作状态, 大家总是需要查询各种库的功能.
> 本教程的目标是有了整体了解后, 大家可以明白自己需要阅读哪些库.

### 参考代码和输出
1. 撸代码的过程中可以看: 2.00拆解实现.ipynb, 这里有所有的每一步的代码
2. 撸完之后, 你的核心代码应该类似这样: 2.00最终实现.ipynb
3. 撸代码的过程中, 会有各种输出, 我们有一个样例输出结果(chrome打开): 样例结果_刺槐.html


### 纯函数手撸
- 先定义整体结构, 一般的机器学习都是这三部分

```python
# 整体结构
# 主函数
def nn():
    # 训练函数
    def train():
        return 'train在这里'
    # 查询函数
    def query():
        return 'query在这里'
    nn.train=train
    nn.query=query

# 此时可以用下面代码测试这个啥也干不了的框架
nn()
nn.train()
```


> 别怕, 代码拢共2步
#### 1/2 初始框架

- 新开一个cell, 逐个尝试下面代码, 一共4部分

```python

# ====== 第一部分/共4部分 矩阵
# 这里引入了一个重要的库
import numpy
# 定义权重矩阵--------------
# 拿到一个随机矩阵
a=numpy.random.rand(3,3)
a
# 此时运行一下, 可以看到a

# 单开一个格子, 减0.5再看看
a=a-0.5
a
# 再运行一下, 看看a, 此时, 可以品味一下, 感受到python的力量了吗?

# 单开一个格子
# 这里引入另一个重要的库, 这个库用来绘图
import matplotlib.pyplot as plt
# 可视化看看
plt.plot(a)

# ====== 第二部分/共4部分 定义参数
# -------ok, 此时我们可以学习如何定义参数了, 单开一个格子----------
# 一个神经网络, 本身需要定义的参数如下两部分:
# a部分. 网络分几层(3层), 每层有几个节点(inputnode, hiddenode, outputnode)
# b部分. 每个节点都有一个权重指标, 因为每个节点都有, 因此这些指标在一起组成了矩阵, 输入层+隐藏层组成了一个矩阵(nn.ih), 隐藏层+输出层组成了另一个矩阵(nn.ho)
# -----后面开始, 逐个定义
# a部分, 
inputnode=3 # 输入层网络节点数量
hiddenode=4 # 隐藏层节点数量
outputnode=5 # 输出层节点数量
nn.inputnode=inputnode # 输入层网络节点数量
nn.hiddenode=hiddenode # 隐藏层节点数量
nn.outputnode=outputnode # 输出层节点数量
# b部分,
# nn.ih定义从输入层到到隐藏层的系数矩阵
# 因为原始的随机数0-1, 用减法调整值域为-0.5到到+0.5
nn.ih = numpy.random.rand(nn.hiddenode,nn.inputnode)-0.5
nn.ho = numpy.random.rand(nn.outputnode,nn.hiddenode)-0.5

# b部分可选项: 
# 正态分布初始化, 简单的说就是让随机性更符合现实的统计规律, 正态的函数是numpy.random.normal(0.0,a, (b,c)), a使用pow(nn.hiddenode, -0.5)是分布数, b,c使用了矩阵维数
nn.ih = numpy.random.normal(0.0, pow(nn.hiddenode, -0.5),(nn.hiddenode, nn.inputnode))
nn.ho = numpy.random.normal(0.0, pow(nn.outputnode, -0.5),(nn.outputnode, nn.hiddenode))
# ------矩阵参数设置大功告成------
# 运行一下这个格子, 运行前可以在最后添加一行代码: nn.xx, 看一下刚刚设置的参数, 例如
nn.ih
# 还可以可视化看看, 开个格子, 运行下面代码
plt.plot(nn.ho)


# ====== 第三部分/共4部分, 矩阵乘法, 单开个格子
# numpy不仅仅可以生成矩阵, 还可以做各种运算
# 矩阵乘法如此简单(矩阵1乘矩阵2), numpy.dot(矩阵一, 矩阵二)
inp= [3,4,5] # 随便定义了一个输入向量
hli=numpy.dot(nn.ih, inp)   # 这里就是矩阵乘法
plt.plot(hli) # 运行一下看看结果


# ====== 第四部分(完) 启动函数
# 导入最后一个重要的库, 科学计算库, 我们准备导入sigma函数
import scipy.special as ss
# 此时, 我们定义启动函数 activation function 就是节点运算的函数
# 启动函数根据需要可以使用不同的各种函数, 此处使用的是s函数(也叫sigma函数), 就是平滑跃迁函数, 详情可以自行看: https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.expit.html
nn.active_f=lambda x: ss.expit(x)
# 这里lambda是一种快捷函数定义, 它很简便优雅, 但是, 只能定义一行函数, 冒号前面是参数, 后面是返回值, 这玩意有lisp内味了.

hlo = nn.active_f(hli) # 这里用启动函数处理了第三部得到的系数矩阵
plt.plot(nn.ho) # 打印一个看看

# 这样隐藏层就处理好了.
# 输出层也是同样的处理方式, 同学们自己思考下......




```
- ================================================
- 代码运行到这里, 伙伴们都理解了他的方法和意义, 那么现在把这些方法都放到函数里面:  
- ================================================

```python
# 主函数
import numpy
import scipy.special
# 这里是主函数的定义, 定义为参数方式, 使用起来更方便
def nn(inputnode, hiddenode, outputnode, learnrate):
    # 定义参数, 网络分为三层, 这里定义每层的节点数--------------
    nn.inputnode=inputnode # 输入层网络节点数量
    nn.hiddenode=hiddenode # 隐藏层节点数量
    nn.outputnode=outputnode # 输出层节点数量
    # 正态分布初始化
    nn.ih = numpy.random.normal(0.0, pow(nn.hiddenode, -0.5),(nn.hiddenode, nn.inputnode))
    nn.ho = numpy.random.normal(0.0, pow(nn.outputnode, -0.5),(nn.outputnode, nn.hiddenode))
    # 启动函数 activation function 就是节点运算的函数
    nn.active_f=lambda x: scipy.special.expit(x)
    nn.learnrate=learnrate # 这个比率是学习的速率
    # 查询函数, 参数是一个list(数组)
    # 未来调用: query([1.0,0.5,-1.5])
    def query(inpl): # inpl是输入向量
        # ----------这里是我偷偷插入的一行, 没什么可讲的, 就是把一维数组(向量), 整理成为二维矩阵
        inp=numpy.array(inpl, ndmin=2).T
        # 矩阵乘法如此简单
        hli=numpy.dot(nn.ih, inp)   # hidden level input
        hlo = nn.active_f(hli) # hidden level output 隐藏层输出等于用s函数处理一下输入
        # 输出层, 一毛一样
        oli=numpy.dot(nn.ho, hlo)
        olo = nn.active_f(oli)
        return olo
    nn.query=query
    # 此句保证可以这样调用: nn.query([1.0,0.5,-1.5])
```
- 上面的代码运行不会有任何结果, 因为只是定义了函数, 因此, 我们要再开一个格子, 运行刚刚定义的函数, 代码如下: 
```python
nn(3,5,2,0.5)
nn.query([1.0,0.5,-1.5])
# 此时执行一下

# 还可以尝试一下下这一句:
query([1.0,0.5,-1.5]) # 这个可能报错(报错是正确结果), 如果没报错, 参见下面的解释
# 这个结果可能让伙伴们大吃一惊, 难道python没有闭包吗?. 难道函数是全局定义的吗? 并不是, 很可能是缓存引起的, del query之后再执行就不可以了. 只能用nn.query([1.0,0.5,-1.5])
```

> 这个格子要多运行几次, 会发现每次结果都不同, 仔细想想为什么?  
> -- 提示, 如果想不通, 就注释一些代码试试, 也可以print中间变量看看情况

#### 2/2 训练网络
> 这个段落出乎意料的简单....... 其实这才揭示了机器学习是非常简单的内容
> 可以在之前预留的train函数的位置写以下代码(喜欢新建一个cell 单独写以下代码, 运行OK之后再搬运会]回预留的function train位置, 也是可以的)
```python
# 首先, 可以把query复制过来, 并且把名字改为train
# 调用方式:  nn.train(ia, targetv)
    def train(inpl,tarl): # inpl是输入向量, tarl是校验向量
        # -----和query一毛一样的5行代码------
        inp=numpy.array(inpl, ndmin=2).T
        hli=numpy.dot(nn.ih, inp)   
        hlo = nn.active_f(hli) 
        oli=numpy.dot(nn.ho, hlo)   
        olo = nn.active_f(oli) 
        # ------从这里开始是不一样的代码了------------
        # 增加了目标数组
        tar=numpy.array(tarl, ndmin=2).T
        # 因为是训练函数, 所以, 我们是有预期结果的, 这种有预期结果的训练就叫: 有监督训练
        nn.learnrate=0.5 # 之前设置的这个比率真的用在了这里, 这个是学习的速率

        # 运算结果就需要做反向传播调整了
        ## 拿到误差
        output_error=tar -olo # 最终结果误差
        # python做矩阵减法, 非常直观

        hidden_error=numpy.dot(nn.ho.T, output_error) 
        # hidden层的误差, 这里又是一次矩阵乘法

        ## 修正权重
        nn.ho += nn.learnrate*numpy.dot( output_error*(olo*(1-olo)), numpy.transpose(hlo))
        # 还记得吗? nn.learnrate 就是一开始设置的学习比率, 这里才用到
        # 主运算符 a+=b 和其他语言一致, 代表 a=a+b, 意思就是隐藏到输出的那个矩阵做一次加法, 对自身进行修正
        # 隐藏层到输出层的权重矩阵 += 学习速率* 矩阵乘法, 这个矩阵乘法的解释如下: 
        # olo*(1-olo)这个是一个S函数, 然后作用于输出误差矩阵, 还记得吗? 启动函数active_f用的也是他
        # hlo要进行转置才能和output_error结果误差做矩阵乘法(点乘)

        # 如果理解了上面那一句, 那么下面是输入到隐藏层的权重调整, 几乎一毛一样
        nn.ih += nn.learnrate*numpy.dot( hidden_error*(hlo*(1-hlo)), numpy.transpose(inp))
    nn.train=train
```
> 大功告成, 代码都完成了. 同样的只是运行函数的定义不会有任何结果, 必须要使用函数才可以, 下面我们开始使用函数

### 用训练数据测试这个神经网络
> 咱们使用手写数字作为目标, 目标是这个神经网络可以识别出手写数字
- 引入训练数据
```python
# --------------训练分2部分-------------
# -----训练第一部分(共2部分): 引入数据文件, 单开一个格子
# 打开文件, 这个文件有十条数据, 文件在群里面, 把它放到你的python notebook所在的目录
dfile=open("./mnist_train_100.csv",'r')
# 读取数据, readlines函数按照[行]读入所有数据
dlist=dfile.readlines()
# 关闭文件
dfile.close()
print(dlist[0])
# 运行一下, 看看结果

# 这个结果很不直观, 因此咱们要绘制数据, 直观看一下, 再开一个格子
# 引入绘图包
import matplotlib.pyplot as plt
# 读第一条数据, 并且格式化成为数组(list)
a=dlist[0].split(',')# 这里dlist[0]代表第一条, 可以换换其他数字试试
print(a[0]) # 看一下这个数组的第一个元素, 这个元素是这个数组实际的数字值
# 此时运行一下

# 再开个格子, 除了第一个数据之外的数据格式化为28*28的矩阵
image_a=numpy.asfarray(a[1:]).reshape((28,28))
# 此处a[1:]是一个切片, 更一般的写法是a[b:c], 意思是a数组中, 从b到c的那些元素, b和c如果是起始点或者终点, 则可以省略
plt.imshow(image_a, cmap='Greys',interpolation='None')
# 这一句话, 就是把这个数组画出来, 按照28*28个像素画出来

# 运行一下, 看看结果

# ----- 训练第二部分(完) 实际训练, 单独再开个格子
# 此时需要调整一波参数: 
# inputnode=28*28 # 输入层网络节点数量, 这个要和输入数据匹配, 我们的输入每一条都是28*28
# hiddenode=100 # 这个是按照经验设置的, 咱们要识别手写数字, 太小的节点量肯定不好, 太大的节电量会导致计算很慢. 这个也是尝试出来的
# outputnode=10 # 因为咱们就识别0-9的数字, 因此, 输出10是很合理的, 理想情况, 其中一个是0.99, 另外几个都是0.01
# learnrate=0.3 # 学习速率, 一般而言越小越好, 但是, 越小计算量越大
# 下面这行代码, 让调整生效让参数生效
nn(28*28, 100, 10, 0.3)
# 训练所有数据
for re in dlist:
    a=re.split(',') # 把字符串用逗号拆成数组
    # 这里是把颜色的数字压缩到0-1之间, 颜色数值一般是0-255, 如果不缩数字持续乘法会导致过大, 大到超过计算机能处理的极限
    ia=(numpy.asfarray(a[1:])/255.0*0.99+0.01)
    # 制造训练的target数据
    targetv=numpy.zeros(nn.outputnode) +0.01 # 整体都初始化为0.01
    # 因为第一个数字是这一行数据的数字, 所以用这个数字做target是非常合理的
    targetv[int(a[0])]=0.99 # 只有目标的值是0.99, 其他值应该都是0.01
    # 开始训练
    nn.train(ia, targetv)
# 好了, 可以测试运行一下, 看看是否有啥拼写错误
# 此时应该没有任何输出, 因此只能看看拼写错误
# 或许会有一个错误: nn.train无法找到, 那么就要回到你定义了整个nn函数的格子, 再次执行一下
# 我们马上进入激动人心的下一步, 检测我们网络的结果
```

### 网络训练好了, 咱们一起见证奇迹
- 新开一个notebook段落, 执行下面的代码, 别怕, 全部都是和以前一样的代码
```python
#----------验证结果-----------
dfile=open("./mnist_test_10.csv",'r')
dlist=dfile.readlines()
dfile.close()
import matplotlib.pyplot
a=dlist[0].split(',')# 这里dlist[0]代表第一条, 可以换换其他数字试试
print(a[0]) # 看一下这个数组的第一个元素, 这个元素是这个数组实际的数字值
image_a=numpy.asfarray(a[1:]).reshape((28,28))
matplotlib.pyplot.imshow(image_a, cmap='Greys',interpolation='None')
# 测试一下这一条数据
ia=(numpy.asfarray(a[1:])/255.0*0.99+0.01)
nn.query(ia) 
# ----------执行上面这段代码------------
# ----------见证奇迹的时刻到了--------------

```

### 思考内容:
1. 简单网络有几部分构成?
2. 神经网络的训练需要哪些组成部分? 
3. 咱们都使用了哪些库? 其中哪些是工作必须的, 哪些是辅助性的?
4. 请大致阅读以下库内容, 看一下简介和wiki即可:
    - numpy, 尤其是矩阵计算内容
    - scipy, 想一下s(sigma)函数如此简单, 为啥要用scipy.special?
    - matplotlib, 这个库的功能是辅助功能, 但是也是python的核心竞争力
    - pandas, 这个库咱们本次没有用到, 但是, 非常重要
5. python的核心竞争力是完善的各种库, 你认同这句话吗? 为什么?