





### 附录: 老旧的class/object风格代码

> 这种实现方式, 使用了class self(其他语言的this) 构造函数(其他语言的new) 继承, 实例化 等等糟糕的概念. 之所以给大家展示这种实现, 是因为, 大量的程序是这么玩的. 木得办法, 为了看懂别人的代码, 只能这样了


```python
import numpy
import scipy.special
class nn:
    def __init__(self, inputnode, hiddenode, outputnode,learnrate):
        self.inode=inputnode
        self.hnode=hiddenode
        self.onode=outputnode
        self.lr=learnrate
        
        # 简单随机初始化
        ## 输入到隐藏的参数矩阵
        self.wih = numpy.random.rand(self.hnode, self.inode)-0.5
        ## 隐藏到输出的参数矩阵
        self.who = numpy.random.rand(self.onode, self.hnode)-0.5
        # 正态分布初始化
        self.wih = numpy.random.normal(0.0, pow(self.hnode, -0.5),(self.hnode, self.inode))
        self.who = numpy.random.normal(0.0, pow(self.onode, -0.5),(self.onode, self.hnode))
        
        # 定义激活函数
        self.act_fun=lambda x: scipy.special.expit(x)
    def train(self, input_list,target_list):
        input_array=numpy.array(input_list, ndmin=2).T
        target_array=numpy.array(target_list, ndmin=2).T

#         print (input_array)
        # 和query一毛一样
        hidden_i= numpy.dot(self.wih, input_array)
#         print (hidden_i)
        hidden_o=self.act_fun(hidden_i)
#         print (hidden_o)
        final_i= numpy.dot(self.who, hidden_o)
#         print (final_i)
        final_o=self.act_fun(final_i)
        
        # 反向传播
        ## 拿到误差
        output_error=target_array -final_o
        hidden_error=numpy.dot(self.who.T, output_error)
        ## 修正权重
        self.who += self.lr*numpy.dot( output_error*(final_o*(1-final_o)), numpy.transpose(hidden_o))
        self.wih += self.lr*numpy.dot( hidden_error*(hidden_o*(1-hidden_o)), numpy.transpose(input_array))


    def query(self, input_list):
        input_array=numpy.array(input_list, ndmin=2).T
#         print (input_array)
        # 这里开始进入随机的世界
        hidden_i= numpy.dot(self.wih, input_array)
#         print (hidden_i)
        hidden_o=self.act_fun(hidden_i)
#         print (hidden_o)
        final_i= numpy.dot(self.who, hidden_o)
#         print (final_i)
        final_o=self.act_fun(final_i)
        return final_o
# 初始化神经网络, 200隐藏层和0.1学习率是实验出来的
input_n=784
hidden_n=200
output_n=10
learn_r=0.1

n=nn(input_n, hidden_n, output_n, learn_r)
# n.query((1.0,0.5,-1.5))

# 引入训练数据
dfile=open("makeyourownneuralnetwork/mnist_dataset/mnist_train.csv",'r')
dlist=dfile.readlines()
dfile.close()

import matplotlib.pyplot
# 多次训练, 5次是一个不错的值, 这玩意是实验出来的
for e in range(5):
    # 训练所有数据
    for re in dlist:
        a=re.split(',')
        ia=(numpy.asfarray(a[1:])/255.0*0.99+0.01)
        #.reshape((28,28))
        # matplotlib.pyplot.imshow(ia, cmap='Greys',interpolation='None')

        # onode=10
        targetv=numpy.zeros(output_n) +0.01
        targetv[int(a[0])]=0.99
        n.train(ia, targetv)
# print(targetv)
    pass
# 测试所有数据
tfile=open("makeyourownneuralnetwork/mnist_dataset/mnist_test.csv",'r')
tlist=tfile.readlines()
tfile.close()

score=[]
errorcheck=[]
for re in tlist:
    a=re.split(',')
#     print(a[0])
    out_re=n.query(numpy.asfarray(a[1:])/255.0*0.99+0.01)
    correct=int(a[0])
    label=numpy.argmax(out_re)
#     print('正确:', correct,'答案:',label)
    if (correct==label):
        score.append(1)
    else:
#         print('正确:', correct,'答案:',label)
        score.append(0)
        errorcheck.append(a)
        # todo 此处不正常, 只画了最后一个图片, 为什么
#         image_a=numpy.asfarray(a[1:]).reshape((28,28))
#         matplotlib.pyplot.imshow(image_a, cmap='Greys',interpolation='None')

scor=numpy.asarray(score)
print('比率: ',scor.sum()/scor.size*100, '%')
print(errorcheck)




```